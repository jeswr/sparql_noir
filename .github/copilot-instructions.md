# Copilot Coding Agent Instructions

Project-specific context for AI agents working in this repo.

## Purpose

Generate zero-knowledge proofs that SPARQL query results are correct, without revealing the underlying signed RDF datasets.

**Core workflow:** `setup` â†’ `sign` â†’ `transform` â†’ `compile` â†’ `prove` â†’ `verify`

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TypeScript (src/scripts/)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ setup.ts    â”‚  â”‚ sign.ts     â”‚  â”‚ prove.ts / verify.ts    â”‚  â”‚
â”‚  â”‚ - Configure â”‚  â”‚ - Sign RDF  â”‚  â”‚ - Generate witness      â”‚  â”‚
â”‚  â”‚   lib/constsâ”‚  â”‚ - Merkle    â”‚  â”‚ - Run nargo/bb.js       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rust Transform (transform/)     â”‚    noir/lib/ (shared libs)    â”‚
â”‚ - SPARQL parsing (spargebra)    â”‚    â”œâ”€â”€ consts/ (hash config)  â”‚
â”‚ - Noir code generation          â”‚    â”œâ”€â”€ types/ (Triple, Root)  â”‚
â”‚ - BGP â†’ constraint mapping      â”‚    â”œâ”€â”€ utils/ (merkle, sig)   â”‚
â”‚ - ZERO hash knowledge           â”‚    â””â”€â”€ signatures/*           â”‚
â”‚ - Generates "hash2(...)"        â”‚                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Generated Circuit (output/)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Nargo.toml          â”‚  â”‚ src/main.nr + src/sparql.nr     â”‚   â”‚
â”‚  â”‚ deps: consts, types â”‚  â”‚ use dep::consts::hash2;         â”‚   â”‚
â”‚  â”‚       utils         â”‚  â”‚ use dep::types::Triple;         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Directory Structure

```
sparql_noir/
â”œâ”€â”€ transform/              # Rust: SPARQL â†’ Noir (ONLY transform, zero hash knowledge)
â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â””â”€â”€ src/main.rs         # SPARQL parsing, Noir code generation
â”œâ”€â”€ noir/
â”‚   â”œâ”€â”€ lib/                # Shared libraries (imported by generated circuits)
â”‚   â”‚   â”œâ”€â”€ consts/         # hash2, hash4, hash_string, MERKLE_DEPTH, signature
â”‚   â”‚   â”œâ”€â”€ types/          # Triple, Root, IndexedRoot, Proof structs
â”‚   â”‚   â”œâ”€â”€ utils/          # verify_inclusion, verify_signature, merkle
â”‚   â”‚   â”œâ”€â”€ signatures/     # schnorr, secp256k1, secp256r1, babyjubjub, bls
â”‚   â”‚   â””â”€â”€ hashes/         # poseidon2, keccak256
â”‚   â””â”€â”€ bin/                # Standalone utility circuits (examples)
â”‚       â”œâ”€â”€ encode/
â”‚       â”œâ”€â”€ signature/
â”‚       â””â”€â”€ verify_inclusion/
â”œâ”€â”€ src/                    # TypeScript: signing, proving, verification
â”‚   â”œâ”€â”€ config.ts
â”‚   â”œâ”€â”€ encode.ts
â”‚   â”œâ”€â”€ mappings.ts
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ setup.ts        # Configure noir/lib/consts (ðŸ†• to create)
â”‚       â”œâ”€â”€ sign.ts         # Sign RDF datasets (âœ… complete)
â”‚       â”œâ”€â”€ prove.ts        # Generate proofs (âš ï¸ needs update)
â”‚       â””â”€â”€ verify.ts       # Verify proofs (âœ… complete)
â”œâ”€â”€ spec/                   # Specification documents
â”‚   â”œâ”€â”€ encoding.md         # RDF term â†’ Field encoding
â”‚   â”œâ”€â”€ algebra.md          # SPARQL pattern â†’ Noir constraint mapping
â”‚   â”œâ”€â”€ proofs.md           # API: sign(), prove(), verify()
â”‚   â”œâ”€â”€ disclosure.md       # What proofs reveal vs hide
â”‚   â””â”€â”€ config.md           # Configurable parameters
â”œâ”€â”€ legacy/                 # Old implementations (reference only)
â””â”€â”€ inputs/                 # Example data and queries
```

## Key Design Principle: Import Over Generation

**Generated circuits MUST import from `noir/lib/`, never inline hash/signature code.**

The Rust transform generates Noir code with function calls like `hash2(...)`, `hash_string(...)`. These resolve to actual implementations at **Noir compile time** based on what's configured in `noir/lib/consts/src/lib.nr`.

```
Rust generates:     "hash2([x, y])"           â† String literal, no hash knowledge
Noir resolves to:   pedersen_hash([x, y])     â† Resolved at compile time
```

## Implementation Status

### âœ… Complete

| Component | Location | Notes |
|-----------|----------|-------|
| Noir shared libs | `noir/lib/*` | consts, types, utils, signatures, hashes |
| Sign script | `src/scripts/sign.ts` | Multi-scheme signing |
| Verify script | `src/scripts/verify.ts` | bb.js verification |
| Rust SPARQL parsing | `transform/src/main.rs` | BGP, JOIN, FILTER, paths |
| Specification docs | `spec/*` | Encoding, algebra, proofs, disclosure, config |

### âš ï¸ Needs Migration

| Task | Current State | Target |
|------|--------------|--------|
| Remove hash refs in Rust | Has `HASH`, `STRING_HASH` consts | Generate literal `"hash2(...)"` |
| Generate Nargo.toml | Not generated | Include deps to `noir/lib/*` |
| OPTIONAL support | In legacy TS | Port to Rust |

### ðŸ†• Needs Implementation

| Task | Location | Reference |
|------|----------|-----------|
| setup.ts | `src/scripts/setup.ts` | Configure `noir/lib/consts/` |
| prove.ts update | `src/scripts/prove.ts` | Port from `legacy/prove.js` |
| E2E test | `package.json` | Full pipeline test |

## Key Files Reference

### Rust Transform (`transform/src/main.rs`)

**Purpose:** Parse SPARQL, generate Noir circuit code.

**Key functions:**
- `handle_patterns()` - Process SPARQL algebra patterns
- `filter_to_noir()` - Convert FILTER to Noir constraints
- `expand_path_to_plans()` - Property path expansion

**CRITICAL:** Rust has ZERO hash implementation knowledge. It generates string literals:
```rust
// CORRECT - generates function reference
format!("hash2([{}, {}])", a, b)

// WRONG - hardcodes hash name (remove these)
format!("{}([{}, {}])", hash_name, a, b)
```

**What to remove:**
```rust
const STRING_HASH: &str = "blake3";      // DELETE
const HASH: &str = "pedersen";           // DELETE
fn hash2_name() -> &'static str { ... }  // DELETE
```

### Noir Libraries (`noir/lib/`)

**consts/src/lib.nr:**
```noir
global MERKLE_DEPTH: u32 = 11;

pub fn hash2(input: [Field; 2]) -> Field {
    std::hash::pedersen_hash(input)  // Configurable via setup.ts
}

pub fn hash4(input: [Field; 4]) -> Field {
    std::hash::pedersen_hash(input)
}

pub fn hash_string<let N: u32>(s: str<N>) -> Field {
    Field::from_le_bytes(std::hash::blake3(s.as_bytes()))
}

pub mod signature {
    pub use dep::signature::*;  // Re-export selected scheme
}
```

**types/src/lib.nr:**
```noir
pub struct Triple<let DEPTH: u32> {
    pub terms: [Field; 4],           // s, p, o, g encoded
    pub path: [Field; DEPTH],        // Merkle proof path
    pub directions: [bool; DEPTH],   // Path directions
}

pub struct Root {
    pub value: Field,
    pub signature: [Field; 64],
}

pub struct IndexedRoot {
    pub value: Field,
    pub signature: [Field; 64],
    pub key_index: u32,
}
```

**utils/src/lib.nr:**
```noir
use crate::consts::{hash2, hash4, MERKLE_DEPTH};

pub fn verify_inclusion<let DEPTH: u32>(triple: Triple<DEPTH>) -> Field {
    let leaf = hash4(triple.terms);
    merkle(leaf, triple.path, triple.directions)
}

pub fn merkle<let N: u32>(leaf: Field, path: [Field; N], directions: [bool; N]) -> Field {
    // Compute Merkle root using hash2
}
```

### TypeScript Scripts (`src/scripts/`)

**sign.ts:** Signs RDF datasets with Merkle tree + signature (complete).

**prove.ts:** Generate ZK proof using bb.js (needs update for new circuit structure).

**verify.ts:** Verify proof using bb.js (complete).

**setup.ts (to create):** Configure `noir/lib/consts/` for hash/signature/depth selection.

### Generated Circuit Structure

**Nargo.toml:**
```toml
[package]
name = "sparql_proof"
type = "bin"

[dependencies]
consts = { path = "../noir/lib/consts" }
types = { path = "../noir/lib/types" }
utils = { path = "../noir/lib/utils" }
```

**src/main.nr:**
```noir
mod sparql;
use dep::types::{Triple, IndexedRoot};
use dep::utils::{verify_inclusion, verify_signature};
use dep::consts::signature::PubKey;

fn main(
    public_keys: [PubKey; 1],
    roots: [IndexedRoot; 1],
    bgp: BGP,
    variables: pub Variables
) {
    // Verify signatures, inclusion, and SPARQL constraints
}
```

**src/sparql.nr:** Query-specific BGP patterns and constraints.

## Encoding (from spec/encoding.md)

```
Enc_t(term) = hash2([type_code, value_encoding])
Enc_Q(s,p,o,g) = hash4([Enc_t(s), Enc_t(p), Enc_t(o), Enc_t(g)])
```

| Term Type | Code |
|-----------|------|
| NamedNode | 0 |
| BlankNode | 1 |
| Literal | 2 |
| Variable | 3 |
| DefaultGraph | 4 |

## SPARQL â†’ Noir Mapping (from spec/algebra.md)

| SPARQL | Noir Circuit |
|--------|--------------|
| BGP triple | Merkle inclusion proof + binding assertions |
| JOIN | Multiple patterns with variable unification |
| UNION | Branch indicators with disjunctive constraints |
| OPTIONAL | Conditional matching with `is_matched` flag |
| FILTER (`=`) | RDFterm-equal: `a == b` (value equality) |
| FILTER (`sameTerm`) | RDF identity: same encoded value |
| Property paths | Bounded expansion to UNION of BGP sequences |

## Configuration Defaults (from spec/config.md)

| Parameter | Default | Notes |
|-----------|---------|-------|
| `hash2`, `hash4` | pedersen_hash | Term/triple encoding |
| `hash_string` | blake3 | String â†’ Field |
| Signature | Schnorr/Grumpkin | Noir native |
| MERKLE_DEPTH | 11 | Max 2048 triples |
| PATH_SEGMENT_MAX | 8 | Max path hops |

## Supported SPARQL Features

| Feature | Status |
|---------|--------|
| SELECT | âœ… |
| BGP | âœ… |
| JOIN | âœ… |
| UNION | âœ… |
| OPTIONAL | âš ï¸ Needs Rust port |
| FILTER (equality, comparison) | âœ… |
| BIND/EXTEND | âœ… |
| Property Paths (+, *, ?, /, \|, ^) | âœ… |
| DISTINCT, LIMIT | âš ï¸ Post-processing |
| GROUP BY, aggregates | âŒ Deferred |

## Disclosure Model (from spec/disclosure.md)

**Always disclosed:** Query, public keys, signature scheme, merkle depth

**Disclosed by SELECT:** Variable bindings (determined by SELECT clause)

**Never disclosed:** Merkle roots, signatures, dataset content

## Build & Run

```sh
# Prerequisites: Node.js, Rust, nargo (Noir 1.0.0-beta.12)
npm install

# Configure hash/signature/depth
npm run setup -- --hash pedersen --sig schnorr --depth 11

# Sign RDF dataset
npm run sign -- --data inputs/data/data.ttl --out signed.json

# Generate Noir circuit from SPARQL
npm run transform -- -q inputs/sparql.rq -o output

# Compile circuit
cd output && nargo compile

# Generate and verify proof
npm run prove -- --circuit output --signed signed.json --out proof.json
npm run verify -- --proof proof.json
```

## Dependencies

- **Rust:** spargebra, spareval, clap, serde_json
- **Noir:** std::hash (pedersen, blake3), poseidon2 (optional)
- **TypeScript:** n3, @noir-lang/noir_js, @aztec/bb.js

## Development Workflow

1. **Read spec/** before making changes to understand formal semantics
2. **Rust transform is hash-agnostic** - never add hash implementation details
3. **Generated circuits import** - never generate inline hash code
4. **Test with `nargo check`** after any Noir library changes
5. **Run E2E** after changes to validate full pipeline
6. **Run transform tests** to verify generated Noir is correct

## Transform Correctness Requirements

**CRITICAL:** The Rust transform generates Noir circuit code. ALL constraint checking MUST happen in the generated Noir code, NOT in Rust at compile time. The Rust transform should only:
1. Parse SPARQL and generate Noir code strings
2. Do minimal constant folding for simple literals
3. Never evaluate filter conditions at Rust compile time

### Generated Circuit Must Include

For a query like `SELECT ?s ?o WHERE { ?s ex:knows ?o . FILTER(?s != ?o) FILTER(?o > 3) }`:

1. **Variables struct** - ONLY projected variables from SELECT clause:
   ```noir
   pub(crate) struct Variables {
     pub(crate) s: Field,
     pub(crate) o: Field,  // NOT 'p' since it's not projected
   }
   ```

2. **Static term checks** - Assert predicates/objects match expected IRIs/literals:
   ```noir
   // ex:knows must be checked
   assert(consts::hash2([0, utils::encode_string("http://example.org/knows")]) == bgp[0].terms[1]);
   ```

3. **Filter constraints in Noir** - ALL filter logic must be Noir assertions:
   ```noir
   // ?s != ?o
   assert((variables.s == variables.o) == false);
   // ?o > 3 - comparison must happen in Noir, not Rust
   assert(variables.o > encoded_literal_3);
   ```

4. **IEEE 754 comparisons** - For float/double special values (NaN, INF, -INF):
   - Constant-to-constant comparisons CAN be folded in Rust
   - Variable comparisons MUST generate Noir code that handles IEEE semantics
   - NaN comparisons: Generate Noir that checks for NaN and returns false
   - INF comparisons: Generate Noir that handles infinity ordering

### Common Transform Bugs to Avoid

| Bug | Symptom | Fix |
|-----|---------|-----|
| Non-projected vars in Variables struct | `p: Field` when `?p` not in SELECT | Only iterate `info.variables` (projected vars) |
| Missing static term assertions | No check for `ex:knows` | Generate assertions for NamedNode predicates/objects |
| Filter evaluated in Rust | `?o > 3` becomes `true`/`false` literal | Generate Noir comparison expression |
| IEEE 754 in Rust only | NaN/INF handled at compile time | Generate Noir code for runtime IEEE semantics |

## Testing Infrastructure

### Snapshot Tests (`test/fixtures/`)

Test that generated `sparql.nr` matches expected output:

```
test/fixtures/
â”œâ”€â”€ basic_bgp/
â”‚   â”œâ”€â”€ query.rq          # Input SPARQL
â”‚   â””â”€â”€ expected.nr       # Expected sparql.nr output
â”œâ”€â”€ filter_comparison/
â”‚   â”œâ”€â”€ query.rq
â”‚   â””â”€â”€ expected.nr
â”œâ”€â”€ static_predicate/
â”‚   â”œâ”€â”€ query.rq
â”‚   â””â”€â”€ expected.nr
â””â”€â”€ ...
```

Run with: `cargo test --manifest-path transform/Cargo.toml`

### Circuit Validity Tests (`test/circuits/`)

Test that generated circuits accept valid inputs and reject invalid ones:

```
test/circuits/
â”œâ”€â”€ basic_bgp/
â”‚   â”œâ”€â”€ query.rq
â”‚   â”œâ”€â”€ valid_inputs/     # Should produce valid proofs
â”‚   â”‚   â””â”€â”€ case1.toml
â”‚   â””â”€â”€ invalid_inputs/   # Should fail circuit constraints
â”‚       â”œâ”€â”€ wrong_predicate.toml
â”‚       â””â”€â”€ filter_fails.toml
â””â”€â”€ ...
```

Run with: `npm run test:circuits`

### Test Categories

1. **Projection tests** - Verify Variables struct contains exactly SELECT vars
2. **Static term tests** - Verify IRIs/literals in patterns generate assertions
3. **Filter tests** - Verify FILTER expressions become Noir constraints
4. **Negative tests** - Verify invalid inputs fail circuit constraints

