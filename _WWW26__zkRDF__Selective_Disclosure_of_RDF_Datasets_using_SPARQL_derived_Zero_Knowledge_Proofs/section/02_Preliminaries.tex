\section{Preliminaires}
\label{sec:prelim}
We briefly cover the fundamental concepts of SPARQL which the {zkRDF} approach uses to achieve selective disclosure of RDF datasets.

\paragraph{RDF~\cite{RDF},} the Resource Description Framework, provides a graph-based data model. 
We re-use the common formalization of RDF datasets from~\cite{DBLP:conf/esws/BraunK25}, provided Appendix~\ref{appendix:rdf} for completeness.
We agree to the choice of semantics for RDF datasets from~\cite{DBLP:conf/esws/BraunK25}:
When merging two RDF datasets, blank nodes between the two RDF datasets must be re-labeled to avoid co-references, and new graph names must be minted for the default graphs of the respective RDF datasets.
% \todo{JW: suggesst replacing with: "Per RDF semantics [insert link] blank nodes are not co-referencable across graphs" and then mention the re-naming as an implementation detail later on}

The Verifiable Credentials (VCs) data model~\cite{VC}, a W3C Recommendation, models assertions and cryptographically assured provenance, \eg digital signatures, as an RDF dataset.
In that RDF dataset, the claims and credential metadata form the unnamed default graph, and a particular claim links to a named graph with corresponding cryptographic provenance information, \ie the proof graph.
\begin{comment}
\todo{JW: Suggest removing everything after this - as it is an opinion/position and draws focus from the paper}Based on our implementation experience, briefly outlined in Section~\ref{sec:eval_performance}, we agree with~\cite{DBLP:conf/esws/BraunK25} that the W3C VC data model should mandate asserting claims in a named graph, and have the proof link to the graph it covers.
\end{comment}
Nanopublications~\cite{DBLP:journals/peerj-cs/KuhnCKQVGNVD16} offer an alternative RDF-based data model where provenance information is modeled in a named graph and linked to a named graph of assertions.

\paragraph{SPARQL~\cite{SPARQL}} is the W3C-recommended query language for RDF. %\todo{check paragraph}
The fundamental component of a SPARQL query is the {Basic Graph Pattern (BGP)}, a set of triple patterns. 
The evaluation of a BGP against an RDF graph yields a multiset of {solution mappings}
Each solution mapping maps variables to RDF terms.
The semantics of complex SPARQL queries are formally defined by an algebra over these multisets of solution mappings. 
One of the key algebraic operators is {\texttt{Filter}}. 
A filter operation reduces the multiset of solution mappings based on an {expression}. %\todo{define expression better?}
Such expressions are constructed from variables, RDF literals, and a set of built-in functions, including logical connectives (\texttt{\&\&}, \texttt{||}), relational comparisons (\texttt{=}, \texttt{<}, \texttt{>}), and type tests (e.g., \texttt{isLiteral()}). % \todo{JW: Consider linking to the point in the spec defining expressions}

\begin{comment}
SPARQL may thus serve as one way to query and filter information with attached cryptographic provenance information.
For example, a SPARQL query may express which VCs should be presented to a verifier and which information therein should be revealed or remain hidden. \todo{JW: Suggest removing this papragaph on filtering cryptographic information - to avoid distraction / confuison}
\end{comment}


\paragraph{Selective disclosure} refers to the concept of proving properties of a dataset while hiding some or all of the data~\cite{Brands2002ATO}.
One way to implement this selective disclosure are zero-knowledge proofs (ZKPs)~\cite{DBLP:conf/stoc/GoldwasserMR85}: A prover is able to convince a verifier that a claim is true without the verifier learning any additional information (zero-knowledge).
An example of a claim is: \texttt{My secret age \textit{w} is greater than 21}.
Terminology-wise, a {claim} consists of the following elements~\cite{DBLP:journals/iacr/CampanelliFQ19}:
What is to be proven is called \textbf{relation}, \ie \texttt{\textit{secret value} greater than \textit{public value}}.
The set of public inputs to the relation is called (proof) \textbf{statement}, \ie \texttt{21}.
The set of private inputs, secret to the prover, is called \textbf{witness}, \eg \texttt{25}.

ZKPs can be used to prove a number of different relations;
proving numeric bounds~\cite{DBLP:journals/iacr/CampanelliFQ19, DBLP:journals/iacr/Eagen22} or set (non-)membership~\cite{DBLP:journals/iacr/VittoB20}.
Or, most common in the domain of VCs is proving knowledge of signature~\cite{DBLP:conf/scn/CamenischL02, DBLP:journals/iacr/CamenischDL16, cryptoeprint:2015/525} on credential data while simultaneous revealing some data in the credential and hiding the remainder.
Proof composition, \ie combinations of ZKPs on the same witness data, is enabled by following the {commit-and-prove scheme}~\cite{DBLP:journals/iacr/CanettiLOS02,DBLP:books/daglib/0066918}.
% \todo{JW: I would move discussion of different ways of performing proof of knowledge of signature to a later section}

\begin{comment}
\todo{JW: I don't think the following 3 paragraphs about comitting to a dataset add to this section. I would argue that it is a fair assumption that data is immutable after sigining. I would delete them.}
When an RDF dataset is digitally signed by an issuer, the data is being committed to \todo{JW: Define "comitted to"}.
The corresponding signature is only valid for the current state of the dataset; the underlying data cannot be changed after the fact.
Then, a prover is able to create a proof, \eg a proof of knowledge of signature or of numeric bounds, about the dataset.
\end{comment}


\section{Related Work}
\label{sec:related}

We acknowledge that provenance surrounding SPARQL has been a long researched field, and yet, to our knowledge, no related work at the intersection of SPARQL and ZKPs exists -- except for one project\footnote{\label{fn:zkVM}\url{https://github.com/jeswr/queryable-credentials}} found on GitHub.
This project takes a computation-centric perspective on query execution, similar to related research on SQL and Cypher.
Taking a data-centric perspective, we examine the intersection of RDF and ZKPs, most relevant for VCs~\cite{VC}.


\paragraph{Computation-centric approaches} to zero-knowledge querying focus on proving the correctness of a result that is computed or aggregated from a dataset. The primary goal is to provide a verifiable answer to an (often analytical) query without revealing the underlying individual data that was used in the computation.

For SPARQL, an explorative work on queryable credentials\footnote{See footnote \ref{fn:zkVM}.} uses a zero-knowledge Virtual Machine (zkVM) to prove the execution and thus results of a query.
% A zkVM is designed to prove the correct execution of arbitrary input programs; one such program can be a SPARQL engine. 
In this SPARQL-in-zkVM approach, the zkVM proves that a SPARQL query engine executed the input SPARQL query correctly.
The query execution is handled within the zkVM and a corresponding execution trace is created as a proof.
In the use case of this work, the dataset includes digitally signed RDF graphs, i.e. VCs.
The program executed within the zkVM also includes a verification of those VCs to prove that the SPARQL results were obtained from digitally signed RDF graphs.
% A check on which issuer signed which data underlying the query results is not (yet) supported in this prototype.

For SQL, the ZKSQL approach~\cite{DBLP:journals/pvldb/LiWXWR23}
aims to prove correct execution of SQL queries on relational databases.
This approach decomposes a query based on the standard relational algebra query plan into SQL operators like \texttt{join}, \texttt{filter}, and \texttt{aggregate}.
It then relies on an interactive ZK proof protocol that requires real-time, back-and-forth communication between the prover and verifier to generate and validate a proof of correct SQL query execution.

% \todo{JW: cite Pponeglyphdb, the writeup on P29 of https://jeswr.solidcommunity.net/public/tos-report-v4-cleaned-2.pdf can be used}

For Cypher, the ZKGraph approach~\cite{DBLP:journals/corr/abs-2507-00427} targets graph databases to prove complex algorithmic operations like pathfinding and multi-hop traversals.
This approach employs an \enquote{expansion-centric} model where a query is broken down to the core primitive, \ie graph traversal (node expansion), and other operations are treated as variations (that have certain \enquote{attributes}) of this primitive.
The prover then generates a single, self-contained proof that the query results had been correctly computed.

\paragraph{Data-centric approaches} to zero-knowledge querying focus on proving that a specific subset of data is authentic and satisfies a set of declarative properties. The primary goal is the selective and verifiable disclosure of data items themselves or properties of them, not a new value computed from them.

A first approach to ZKPs on RDF-based credentials~\cite{DBLP:conf/eurosp/YamamotoSS22} only allows selective disclosure of complete triples of an RDF graph.
Proofs on individual RDF terms of a triple are not possible.
The current Data Integrity BBS Cryptosuites~\cite{w3c-vc-di-bbs-2025}, a Candidate Recommendation Draft by the W3C Verifiable Credentials Working Group, follows a similar approach.

Considering RDF-based semantics~\cite{DBLP:conf/esws/BraunK25} provides a more granular approach for selective disclosure: This approach allows to selectively disclose RDF terms within a quad of
an RDF dataset, \eg to prove numeric bounds or set (non-)membership on individual RDF terms; or equality of RDF terms across quads.
Moreover, in this approach, it is proven to be logically sound to
query and to reason on VCs and their presentations, even when using ZKPs.
This paper builds on the semantic foundations provided in~\cite{DBLP:conf/esws/BraunK25} and extends it by enabling definition of what to prove using SPARQL.


In the particular domain of digital credentials, the standard for querying is the Digital Credentials Query Language (DCQL) -- not SPARQL.
DCQL is a JSON-based language defined by the recent OpenID4VP standard~\cite{openID4VP}.
It aims to provide a credential-format independent way to express which credential(s) or data therein should be presented to a verifier.
DCQL is deliberately limited: A verifier can only ask for credentials in a restricted way to prevent data leakage and to protect the user.
From the current specification, it seems that only queries for particular credentials, credential formats, and attested attributes can be specified.
DCQL thus does not seem to support definition of numeric bounds or set (non-)membership.
The approach presented in this paper, however, is not limited to the use case (and data model) of VCs, but it is a rather general approach to prove correctness of SPARQL query results from digitally signed RDF datasets using ZKPs.
